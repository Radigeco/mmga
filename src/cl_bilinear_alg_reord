MMKERNELSRC(

    __kernel void cl_bilinear_alg(
        __global float * A,
        __global float * B,
        __global float * C,
        __global int * g_sigma,
        __global int * g_delta,
        __global float * reserved,
        __global float * R) // eredmeny
{
    __private int index = get_global_id(0);
    __private int sigma = *g_sigma;
    __private int delta = *g_delta;
    __private int delta2 = delta * delta;
    __private int mat_offset = index * delta2 * sigma;
    __private float s1, s2;
    __private float err = 0;
    __local float a[207], b[207], c[207];

	//improvement on cl_bilinear_alg_local:
    //reorder elements, such that the very inner loop in r accesses adjacent values

	for (int ij = 0, k = 0; ij < delta2; ++ij)
	{
		for (int r = 0; r < sigma; ++r, ++k)
		{
			int idx = mat_offset + delta2 * r + ij;
            a[k] = A[idx];
            b[k] = B[idx];
            c[k] = C[idx];
		}
	}

    for (int i = 0; i < delta; ++i)
    {
        for (int j = 0; j < delta; ++j)
        {
            for (int k = 0; k < delta; ++k)
            {
                for (int l = 0; l < delta; ++l)
                {
                    for (int m = 0; m < delta; ++m)
                    {
                        for (int n = 0; n < delta; ++n)
                        {
                            s1 = (n == i) * (j == k) * (l == m);
                            s2 = 0;

                            int ij = sigma * (i * delta + j);
                            int kl = sigma * (k * delta + l);
                            int mn = sigma * (m * delta + n);

                            for (int r = 0; r < sigma; ++r)
                                s2 += a[ij + r] * b[kl + r] * c[mn + r];

                            err += (s2 - s1) * (s2 - s1);
                        }
                    }
                }
            }
        }
    }


    R[index] = 1.0f / (1.0f + err);
}

);
